#!/usr/bin/env python3

import argparse
import dataclasses
import datetime
import io
import logging
import os
import pathlib
import platform
import shlex
import shutil
import string
import subprocess
import sys
import textwrap
import time
import typing


class ContainerEngine:
    _cached_engine: str | None = None

    @classmethod
    def _detect(cls) -> str:
        if cls._cached_engine is None:
            env_engine = os.environ.get('CONTAINER_ENGINE')
            if env_engine:
                if shutil.which(env_engine):
                    cls._cached_engine = env_engine
                else:
                    raise RuntimeError(f'CONTAINER_ENGINE={env_engine} not found in PATH')
            elif shutil.which('podman'):
                cls._cached_engine = 'podman'
            elif shutil.which('docker'):
                cls._cached_engine = 'docker'
            else:
                raise RuntimeError('no container engine found (docker or podman)')
        return cls._cached_engine

    @classmethod
    def cmd(cls, *args: str) -> list[str]:
        return [cls._detect(), *args]

    @classmethod
    def engine(cls) -> str:
        return cls._detect()

    @classmethod
    def image_prune_cmd(cls) -> list[str]:
        return [cls._detect(), 'image', 'prune', '-f']


@dataclasses.dataclass
class Tool:
    setup: list[str] = dataclasses.field(default_factory=list)
    depends_on: list[str] = dataclasses.field(default_factory=list)
    env: list[dict[str, str]] = dataclasses.field(default_factory=list)
    copy: list[dict[str, str]] = dataclasses.field(default_factory=list)


@dataclasses.dataclass
class DistroConfig:
    name: str
    pkg_format: str
    base_image: str
    pkg_install: str
    pkg_install_flags: str
    pkg_update: str

    def install(self, *packages: str) -> str:
        pkgs = ' '.join(packages)
        if self.pkg_install_flags:
            return f'{self.pkg_install} {pkgs} {self.pkg_install_flags}'
        return f'{self.pkg_install} {pkgs}'

    def install_nosudo(self, *packages: str) -> str:
        pkgs = ' '.join(packages)
        cmd = self.pkg_install.removeprefix('sudo ')
        if self.pkg_install_flags:
            return f'{cmd} {pkgs} {self.pkg_install_flags}'
        return f'{cmd} {pkgs}'

    def docker_install_cmd(self) -> str:
        raise NotImplementedError('subclass must implement docker_install_cmd')

    def gcc_package(self) -> str:
        raise NotImplementedError('subclass must implement gcc_package')

    def sysutils_packages(self) -> list[str]:
        raise NotImplementedError('subclass must implement sysutils_packages')

    def mirror_config(self) -> str:
        raise NotImplementedError('subclass must implement mirror_config')


class DebianDistroConfig(DistroConfig):
    def __init__(self):
        super().__init__(
            name='debian',
            pkg_format='deb',
            base_image='debian:bookworm',
            pkg_install='sudo apt install -y',
            pkg_install_flags='',
            pkg_update='apt update && apt upgrade -y',
        )

    def docker_install_cmd(self) -> str:
        return textwrap.dedent("""
            sudo install -m 0755 -d /etc/apt/keyrings && \\
            sudo curl -fsSL https://download.docker.com/linux/debian/gpg -o /etc/apt/keyrings/docker.asc && \\
            sudo chmod a+r /etc/apt/keyrings/docker.asc && \\
            echo \\
              "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/debian \\
              $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | \\
              sudo tee /etc/apt/sources.list.d/docker.list > /dev/null && \\
            sudo apt-get update -y && \\
            sudo apt-get install docker-ce-cli -y
        """).strip()

    def gcc_package(self) -> str:
        return 'build-essential'

    def sysutils_packages(self) -> list[str]:
        return ['procps', 'iproute2']

    def mirror_config(self) -> str:
        return 'echo "Acquire::Retries \\"3\\";" > /etc/apt/apt.conf.d/80-retries'


class RpmDistroConfig(DistroConfig):
    def docker_install_cmd(self) -> str:
        return textwrap.dedent("""
            sudo dnf -y install dnf-plugins-core && \\
            sudo dnf config-manager --add-repo https://download.docker.com/linux/rhel/docker-ce.repo && \\
            sudo dnf install -y docker-ce-cli
        """).strip()

    def gcc_package(self) -> str:
        return 'gcc'

    def sysutils_packages(self) -> list[str]:
        return ['procps', 'iproute']

    def mirror_config(self) -> str:
        return 'echo "fastestmirror=True" >> /etc/dnf/dnf.conf && echo "max_parallel_downloads=10" >> /etc/dnf/dnf.conf'


class AlmaDistroConfig(RpmDistroConfig):
    def __init__(self):
        super().__init__(
            name='alma',
            pkg_format='rpm',
            base_image='almalinux:9',
            pkg_install='sudo dnf install -y',
            pkg_install_flags='--skip-broken',
            pkg_update='dnf update -y',
        )


class FedoraDistroConfig(RpmDistroConfig):
    def __init__(self):
        super().__init__(
            name='fedora',
            pkg_format='rpm',
            base_image='fedora:41',
            pkg_install='sudo dnf install -y',
            pkg_install_flags='',
            pkg_update='dnf update -y',
        )


class CudaDistroConfig(RpmDistroConfig):
    def __init__(self):
        super().__init__(
            name='cuda',
            pkg_format='rpm',
            base_image='nvidia/cuda:11.8.0-runtime-ubi8',
            pkg_install='sudo dnf install -y',
            pkg_install_flags='--skip-broken',
            pkg_update='dnf update -y',
        )


def resolve_dependencies(tools: dict[str, Tool], selected: list[str]) -> list[str]:
    resolved: list[str] = []
    visited: set[str] = set()
    in_stack: set[str] = set()

    def visit(name: str) -> None:
        if name in visited:
            return
        if name in in_stack:
            raise ValueError(f'circular dependency detected: {name}')
        if name not in tools:
            raise ValueError(f'unknown tool: {name}')

        in_stack.add(name)
        for dep in tools[name].depends_on:
            visit(dep)
        in_stack.remove(name)
        visited.add(name)
        resolved.append(name)

    for tool_name in selected:
        visit(tool_name)

    return resolved


def _init_logger():
    debug_enabled = os.environ.get('DEBUG', '').lower() in ('1', 'true')
    level = logging.DEBUG if debug_enabled else logging.INFO

    logger = logging.getLogger('dnv')
    if logger.handlers:
        logger.setLevel(level)
        for handler in logger.handlers:
            handler.setLevel(level)
        return logger

    logger.setLevel(level)
    logger.propagate = False
    fmt = logging.Formatter('%(asctime)s | %(levelname)s | %(message)s')

    console_handler = logging.StreamHandler()
    console_handler.setFormatter(fmt)
    console_handler.setLevel(level)
    logger.addHandler(console_handler)

    if debug_enabled:
        log_dir = pathlib.Path.home() / '.dotfiles' / '.logs' / 'dnv'
        log_dir.mkdir(parents=True, exist_ok=True)
        log_file = log_dir / f'dnv_{datetime.datetime.now().strftime("%Y%m%d_%H%M%S")}.log'
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setFormatter(fmt)
        file_handler.setLevel(level)
        logger.addHandler(file_handler)
        logger.debug('logger initialized (level=%s) file=%s', logging.getLevelName(level), log_file)

    return logger


logger = _init_logger()


def get_host_architecture() -> str:
    machine = platform.machine().lower()
    if machine in ('x86_64', 'amd64'):
        return 'x86_64'
    elif machine in ('aarch64', 'arm64'):
        return 'aarch64'
    else:
        return 'x86_64'


def get_docker_platform_flag(profile_arch: str) -> list[str]:
    host_arch = get_host_architecture()
    if host_arch != profile_arch:
        if profile_arch == 'x86_64':
            return ['--platform', 'linux/amd64']
        elif profile_arch == 'aarch64':
            return ['--platform', 'linux/arm64']
    return []


class DockerfileTemplate(string.Template):
    delimiter = '<$>'


class DevEnvironmentConfig:
    DISTROS: dict[str, DistroConfig] = {
        'debian': DebianDistroConfig(),
        'alma': AlmaDistroConfig(),
        'fedora': FedoraDistroConfig(),
        'cuda': CudaDistroConfig(),
    }

    PROFILES: dict[str, dict[str, typing.Any]] = {
        'just-dotfiles': {
            'dotfiles': [
                '.bashrc',
                '.bash_profile',
                '.tmux.conf',
                '.haskeline',
                '.ruff.toml',
                '.vimrc',
                '.visidatarc',
                '.ipython',
                '.config/starship.toml',
                '.config/nvim',
                '.config/.ghc',
                '.config/kitty',
                '.config/mpv',
            ]
        },
        'workstation': {
            'distro': 'alma',
            'arch': 'x86_64',
            'container_user': 'blue',
            'volumes': [
                {'source': '~/.ssh', 'target': '/home/blue/.ssh', 'mode': 'ro'},
            ],
            'tools': [
                'python',
                'node',
                'rust',
                'go',
                'sdkman',
                'neovim',
                'starship',
                'fzf',
                'ripgrep',
                'tokei',
                'eza',
                'kubectl',
                'ipython',
                'ranger',
                'sysutils',
                'ssh',
                'docker',
                'dotfiles',
            ],
            'dotfiles': [
                '.bashrc',
                '.bash_profile',
                '.config/starship.toml',
                '.config/nvim',
                '.tmux.conf',
            ],
        },
        'workstation-arm': {
            'distro': 'alma',
            'arch': 'aarch64',
            'container_user': 'blue',
            'volumes': [
                {'source': '~/.ssh', 'target': '/home/blue/.ssh', 'mode': 'ro'},
            ],
            'tools': [
                'git',
                'make',
                'gcc',
                'vim',
                'python',
                'node',
                'rust',
                'go',
                'sdkman',
                'neovim',
                'starship',
                'fzf',
                'ripgrep',
                'tokei',
                'eza',
                'kubectl',
                'ipython',
                'ranger',
                'sysutils',
                'ssh',
                'docker',
                'dotfiles',
            ],
            'dotfiles': [
                '.bashrc',
                '.config/starship.toml',
                '.config/nvim',
                '.tmux.conf',
            ],
        },
        'python-minimal': {
            'distro': 'alma',
            'arch': 'x86_64',
            'container_user': 'blue',
            'exposed_ports': [8000],
            'volumes': [{'source': '~/code', 'target': '/home/blue/code', 'mode': 'rw'}],
            'tools': ['python', 'fzf', 'ripgrep', 'ipython', 'dotfiles'],
            'dotfiles': ['.bashrc', '.gitconfig'],
        },
        'python-minimal-arm': {
            'distro': 'alma',
            'arch': 'aarch64',
            'container_user': 'blue',
            'exposed_ports': [8000],
            'volumes': [{'source': '~/code', 'target': '/home/blue/code', 'mode': 'rw'}],
            'tools': ['python', 'fzf', 'ripgrep', 'ipython', 'dotfiles'],
            'dotfiles': ['.bashrc', '.gitconfig'],
        },
        'ml-cuda': {
            'distro': 'cuda',
            'arch': 'x86_64',
            'container_user': 'developer',
            'working_directory': '/home/developer/workspace',
            'volumes': [
                {
                    'source': './ml-workspace',
                    'target': '/home/developer/workspace',
                    'mode': 'rw',
                }
            ],
            'dotfiles': ['.bashrc', '.vimrc', '.gitconfig'],
            'tools': ['python', 'starship', 'neovim', 'dotfiles'],
        },
    }

    @classmethod
    def from_profile(cls, profile: str) -> 'DevEnvironmentConfig':
        profile_data = cls.PROFILES.get(profile)
        if not profile_data:
            available = list(cls.PROFILES.keys())
            raise ValueError(f"profile '{profile}' not found. available profiles: {available}")

        return cls(
            distro=profile_data.get('distro', 'alma'),
            arch=profile_data.get('arch', 'x86_64'),
            username=profile_data.get('container_user', 'blue'),
            profile=profile,
        )

    def __init__(
        self,
        distro: str = 'alma',
        arch: str = 'x86_64',
        username: str = 'blue',
        profile: str | None = None,
    ) -> None:
        self.distro = distro
        self.username = username
        self.profile = profile

        # Version constants
        self.versions = {
            'go': 'go1.23.9',
            'uv': '0.7.9',
            'pnpm': '9.15.9',
            'kubectl': 'v1.33.1',
            'nvm': 'v0.39.2',
            'eza': 'v0.21.1',
            'neovim': '0.11.0',
            'fzf': '0.56.3',
            'ripgrep': '14.1.1',
            'tokei': '12.1.2',
        }

        # Architecture mappings
        self.arch_mappings = {
            'x86_64': {
                'go_arch': 'amd64',
                'kubectl_arch': 'amd64',
                'eza_target': 'x86_64-unknown-linux-gnu',
                'nvim_arch': 'x86_64',
                'fzf_arch': 'amd64',
                'ripgrep_arch': 'x86_64-unknown-linux-musl',
                'tokei_arch': 'x86_64-unknown-linux-gnu',
            },
            'aarch64': {
                'go_arch': 'arm64',
                'kubectl_arch': 'arm64',
                'eza_target': 'aarch64-unknown-linux-gnu',
                'nvim_arch': 'arm64',
                'fzf_arch': 'arm64',
                'ripgrep_arch': 'aarch64-unknown-linux-gnu',
                'tokei_arch': 'aarch64-unknown-linux-gnu',
            },
        }

        self.host_arch = arch
        self.current_arch_map = self.arch_mappings.get(self.host_arch, self.arch_mappings['x86_64'])

        self._setup_distro_config()
        self.conf = self._generate_conf()

    def get_profile_data(self) -> dict:
        if self.profile and self.profile in self.PROFILES:
            return self.PROFILES[self.profile]
        return {}

    def _setup_distro_config(self) -> None:
        if self.distro not in self.DISTROS:
            raise ValueError(f'unsupported distro: {self.distro}. supported: {list(self.DISTROS.keys())}')

        self.current_distro_config = self.DISTROS[self.distro]

    def _generate_conf(self) -> dict[str, Tool]:
        pkg = self.current_distro_config
        arch = self.current_arch_map
        v = self.versions

        all_tools: dict[str, Tool] = {
            'curl': Tool(
                setup=[pkg.install('curl')],
            ),
            'tar': Tool(
                setup=[pkg.install('tar')],
            ),
            'unzip': Tool(
                setup=[pkg.install('unzip')],
            ),
            'zip': Tool(
                setup=[pkg.install('zip')],
            ),
            'git': Tool(
                setup=[pkg.install('git')],
            ),
            'make': Tool(
                setup=[pkg.install('make')],
            ),
            'gcc': Tool(
                setup=[pkg.install(pkg.gcc_package())],
            ),
            'vim': Tool(
                setup=[pkg.install('vim')],
            ),
            'ranger': Tool(
                depends_on=['python'],
                setup=['uv tool install ranger-fm'],
            ),
            'sysutils': Tool(
                setup=[pkg.install(*pkg.sysutils_packages())],
            ),
            'openssh': Tool(
                setup=[pkg.install('openssh-server')],
            ),
            'python': Tool(
                depends_on=['curl'],
                env=[{'PATH': '$HOME/.local/bin:$PATH'}],
                setup=[f'curl -LsSf https://astral.sh/uv/{v["uv"]}/install.sh | sh && uv python install 3.11 3.13'],
            ),
            'node': Tool(
                depends_on=['curl'],
                setup=[
                    f"""curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/{v['nvm']}/install.sh | bash && \\
                    export NVM_DIR=$HOME/.nvm && \\
                    source $NVM_DIR/nvm.sh && nvm install 22"""
                ],
            ),
            'rust': Tool(
                depends_on=['curl'],
                setup=['curl https://sh.rustup.rs -sSf | bash -s -- -y --no-modify-path'],
                env=[{'PATH': '$PATH:$HOME/.cargo/bin'}],
            ),
            'go': Tool(
                depends_on=['curl', 'tar'],
                setup=[
                    f"""curl -LO https://go.dev/dl/{v['go']}.linux-{arch['go_arch']}.tar.gz && \\
                    sudo rm -rf /usr/local/go && sudo tar -C /usr/local -xzf {v['go']}.linux-{arch['go_arch']}.tar.gz && \\
                    rm {v['go']}.linux-{arch['go_arch']}.tar.gz && \\
                    echo 'export PATH=$PATH:/usr/local/go/bin' >> $HOME/.bashrc""",
                ],
                env=[{'PATH': '$PATH:/usr/local/go/bin'}],
            ),
            'sdkman': Tool(
                depends_on=['curl', 'unzip', 'zip'],
                setup=['curl -s "https://get.sdkman.io" | bash'],
            ),
            'pnpm': Tool(
                depends_on=['curl', 'node'],
                setup=[f'curl -fsSL https://get.pnpm.io/install.sh | env PNPM_VERSION={v["pnpm"]} sh -'],
            ),
            'ipython': Tool(
                depends_on=['python'],
                setup=['uv tool install --python 3.11 ipython'],
            ),
            'neovim': Tool(
                depends_on=['curl', 'tar'],
                setup=[
                    f"""curl -LO https://github.com/neovim/neovim/releases/download/v{v['neovim']}/nvim-linux-{arch['nvim_arch']}.tar.gz && \\
                    sudo rm -rf /opt/nvim && sudo tar -C /opt -xzf nvim-linux-{arch['nvim_arch']}.tar.gz && \\
                    sudo ln -sf /opt/nvim-linux-{arch['nvim_arch']}/bin/nvim /usr/local/bin/nvim && \\
                    rm nvim-linux-{arch['nvim_arch']}.tar.gz"""
                ],
            ),
            'starship': Tool(
                depends_on=['curl'],
                setup=['curl -sS https://starship.rs/install.sh | sh -s -- -y && mkdir -p $HOME/.config'],
            ),
            'fzf': Tool(
                depends_on=['curl', 'tar'],
                setup=[
                    f"""curl -LO https://github.com/junegunn/fzf/releases/download/v{v['fzf']}/fzf-{v['fzf']}-linux_{arch['fzf_arch']}.tar.gz && \\
                    tar -xzf fzf-{v['fzf']}-linux_{arch['fzf_arch']}.tar.gz && \\
                    sudo mv fzf /usr/local/bin/ && rm fzf-{v['fzf']}-linux_{arch['fzf_arch']}.tar.gz"""
                ],
            ),
            'ripgrep': Tool(
                depends_on=['curl', 'tar'],
                setup=[
                    f"""curl -LO https://github.com/BurntSushi/ripgrep/releases/download/{v['ripgrep']}/ripgrep-{v['ripgrep']}-{arch['ripgrep_arch']}.tar.gz && \\
                    tar -xzf ripgrep-{v['ripgrep']}-{arch['ripgrep_arch']}.tar.gz && \\
                    sudo mv ripgrep-{v['ripgrep']}-{arch['ripgrep_arch']}/rg /usr/local/bin/ && \\
                    rm -rf ripgrep-{v['ripgrep']}-{arch['ripgrep_arch']}*"""
                ],
            ),
            'tokei': Tool(
                depends_on=['curl', 'tar'],
                setup=[
                    f"""curl -LO https://github.com/XAMPPRocky/tokei/releases/download/v{v['tokei']}/tokei-{arch['tokei_arch']}.tar.gz && \\
                    tar -xzf tokei-{arch['tokei_arch']}.tar.gz && \\
                    sudo mv tokei /usr/local/bin/ && rm tokei-{arch['tokei_arch']}.tar.gz"""
                ],
            ),
            'eza': Tool(
                depends_on=['curl', 'tar'],
                setup=[
                    f"""curl -L https://github.com/eza-community/eza/releases/download/{v['eza']}/eza_{arch['eza_target']}.tar.gz | tar -xz -C /tmp && \\
                    sudo mv /tmp/eza /usr/local/bin/"""
                ],
            ),
            'kubectl': Tool(
                depends_on=['curl'],
                setup=[
                    f"""curl -LO https://dl.k8s.io/release/{v['kubectl']}/bin/linux/{arch['kubectl_arch']}/kubectl && \\
                    sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl && rm kubectl"""
                ],
            ),
            'ssh': Tool(
                depends_on=['openssh'],
                setup=[
                    """sudo sed -i 's/^#*PermitRootLogin.*/PermitRootLogin yes/' /etc/ssh/sshd_config && \\
                    sudo sed -i 's/^#*PasswordAuthentication.*/PasswordAuthentication yes/' /etc/ssh/sshd_config && \\
                    sudo sed -i 's/^#*UsePAM.*/UsePAM yes/' /etc/ssh/sshd_config && \\
                    sudo ssh-keygen -A"""
                ],
            ),
            'docker': Tool(
                depends_on=['curl'],
                setup=[pkg.docker_install_cmd()],
            ),
            'dotfiles': Tool(
                depends_on=['python'],
                copy=[{'source': '.', 'destination': '.dotfiles/'}],
                setup=[
                    'ls ~/.dotfiles/',
                    f'uvx python3.11 ~/.dotfiles/scripts/dnv dotsync --source-dir=~/.dotfiles/ --profile={self.profile}',
                ]
                if self.profile
                else [],
            ),
            'cleanup': Tool(
                setup=[
                    pkg.install_nosudo('clean', 'all')
                    if pkg.pkg_format == 'rpm'
                    else 'sudo apt-get clean && sudo rm -rf /var/lib/apt/lists/*'
                ],
            ),
        }

        if self.profile and self.profile in self.PROFILES:
            profile_data = self.PROFILES[self.profile]
            tools_to_include = profile_data.get('tools', [])
            resolved_order = resolve_dependencies(all_tools, tools_to_include)
            return {name: all_tools[name] for name in resolved_order}

        return all_tools


def normalize_indent_after_first_line(s: str, indent: int = 4) -> str:
    lines = s.splitlines()
    if not lines:
        return s

    first_line = lines[0]
    rest_lines = lines[1:]

    normalized = [first_line]
    for line in rest_lines:
        if line.strip() == '':
            normalized.append('')
        else:
            normalized.append(' ' * indent + line.lstrip())

    return '\n'.join(normalized)


class DockerfileBuilder:
    DOCKERFILE_BASE_TEMPLATE = textwrap.dedent("""
        # NOTE: This Dockerfile is generated. Do not edit manually.
        FROM <$>base_image
        SHELL ["/bin/bash", "-euo", "pipefail", "-c"]
        ENV SHELL=/bin/bash

        RUN <$>mirror_configure && \\
            <$>update && \\
            <$>install_sudo

        ARG USERNAME=<$>username
        ARG USER_UID=1000
        ARG USER_GID=$USER_UID

        RUN groupadd --gid $USER_GID $USERNAME \\
            && useradd --uid $USER_UID --gid $USER_GID -m $USERNAME \\
            && echo $USERNAME ALL=\\(root\\) NOPASSWD:ALL > /etc/sudoers.d/$USERNAME \\
            && chmod 0440 /etc/sudoers.d/$USERNAME

        USER $USERNAME

        WORKDIR <$>workdir

        ENV HOME=<$>workdir

        <$>tool_stages

        # SecretsUsedInArgOrEnv: Do not use ARG or ENV instructions for sensitive data
        ARG PASSWORD=admin
        RUN echo "${USERNAME}:${PASSWORD}" | sudo chpasswd
    """)

    def __init__(self, config: DevEnvironmentConfig) -> None:
        self.config = config
        self.tools = config.conf
        self.docker_template = self._setup_docker_template()

    def _setup_docker_template(self) -> DockerfileTemplate:
        base_template = DockerfileTemplate(textwrap.dedent(self.DOCKERFILE_BASE_TEMPLATE).strip())
        cfg = self.config.current_distro_config

        return DockerfileTemplate(
            base_template.safe_substitute(
                base_image=cfg.base_image,
                mirror_configure=cfg.mirror_config(),
                update=cfg.pkg_update,
                install_sudo=cfg.install_nosudo('sudo'),
                username=self.config.username,
                workdir='/home/$USERNAME',
            )
        )

    def build_tool_stage(self, name: str, tool: Tool) -> str:
        buf = io.StringIO()
        buf.write(f'# stage: {shlex.quote(name)}\n')

        if tool.env:
            buf.write(f'# setting Env for {name}\n')
            for cmd in tool.env:
                for key, val in cmd.items():
                    buf.write(f'ENV {key}={val}\n')
            buf.write('\n')

        if tool.copy:
            buf.write(f'# file copy for {name}\n')
            for f in tool.copy:
                buf.write(f'COPY --chown=$USERNAME:$USERNAME {f["source"]} {f["destination"]}\n')

        if tool.setup:
            buf.write(f'# setup for {name}\n')
            for cmd in tool.setup:
                buf.write(f'RUN {normalize_indent_after_first_line(cmd)}\n')
            buf.write('\n')

        return buf.getvalue()

    def build(self) -> str:
        stages = []
        for name, tool in self.tools.items():
            stages.append(self.build_tool_stage(name, tool))
        return self.docker_template.substitute(tool_stages='\n'.join(stages))


class SetupShBuilder:
    SETUP_SH_BASE_TEMPLATE = textwrap.dedent("""
        #!/bin/bash

        $tool_functions

        $main_cli
    """)

    MAIN_CLI = textwrap.dedent("""
        function install_deps() {
            echo "Installing base dependencies..."
            # This function can be customized to install any base dependencies
            # that are needed before running the individual tool functions
        }

        if [ \"$1\" == \"--install\" ]; then
            shift
            install_deps
            for tool in \"$@\"; do
                if declare -f \"$tool\" > /dev/null; then
                    \"$tool\"
                else
                    echo "Error: Unknown tool '$tool'"
                    exit 1
                fi
            done
        else
            echo "Usage: $0 --install tool1 tool2 ..."
            exit 1
        fi
    """)

    def __init__(self, config: DevEnvironmentConfig) -> None:
        self.config = config
        self.tools = config.conf

    def build_tool_function(self, name: str, tool: Tool) -> str:
        buf = io.StringIO()
        buf.write(f'function {name} {{\n')

        if tool.copy:
            buf.write(f'    # file copy for {name}\n')
            for f in tool.copy:
                buf.write(f'    mkdir -p $(dirname {shlex.quote(f["destination"])})\n')
                buf.write(f'    cp {shlex.quote(f["source"])} {shlex.quote(f["destination"])}\n')

        if tool.setup:
            buf.write(f'    # setup for {name}\n')
            for cmd in tool.setup:
                buf.write(f'    {normalize_indent_after_first_line(cmd, indent=8)}\n')

        buf.write('}\n')
        return buf.getvalue()

    def build(self) -> str:
        functions = [self.build_tool_function(name, tool) for name, tool in self.tools.items()]
        return string.Template(self.SETUP_SH_BASE_TEMPLATE).substitute(
            tool_functions='\n'.join(functions), main_cli=self.MAIN_CLI
        )


class DotfilesManager:
    def __init__(self, dotfiles_dir: pathlib.Path | None = None) -> None:
        self.dotfiles_dir = dotfiles_dir or (pathlib.Path.home() / '.dotfiles')
        self.home_dir = pathlib.Path.home()
        self.backup_dir = self.home_dir / f'.dotfiles-backup-{datetime.datetime.now().strftime("%Y%m%d-%H%M%S")}'

    def create_symlink(self, source: pathlib.Path, target: pathlib.Path) -> None:
        target.parent.mkdir(parents=True, exist_ok=True)

        # TODO: don't do auto backup
        if target.exists() and not target.is_symlink():
            self.backup_dir.mkdir(parents=True, exist_ok=True)
            backup_path = self.backup_dir / target.name
            logger.info(f'backing up existing {target} to {backup_path}')
            shutil.move(str(target), str(backup_path))
        elif target.is_symlink():
            target.unlink()

        target.symlink_to(source)
        logger.info(f'created symlink: {target} -> {source}')

    def install_dotfiles(self, files: list[str], source_dir: str | None = None) -> None:
        if source_dir:
            source_base = pathlib.Path(source_dir).expanduser().resolve()
        else:
            source_base = self.dotfiles_dir

        target_base = self.home_dir

        for file_path in files:
            source = source_base / file_path
            target = target_base / file_path

            if not source.exists():
                logger.warning(f"source file doesn't exist: {source}")
                continue

            try:
                self.create_symlink(source, target)
            except Exception as e:
                logger.error(f'error creating symlink for {file_path}: {e}')


class ArtifactRepository:
    def __init__(self, output_dir: str = '~/.dotfiles/.devenv/'):
        self.output_dir = pathlib.Path(output_dir).expanduser().resolve()
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.logs_dir = self.output_dir / 'logs'
        self.logs_dir.mkdir(parents=True, exist_ok=True)
        self.main_log_file = self.logs_dir / 'dnv.log'
        if not self.main_log_file.exists():
            try:
                self.main_log_file.touch()
            except Exception as e:
                logger.debug(f'could not create main log file: {e}')

    def save_artifact(self, content: str, filename: str) -> pathlib.Path:
        filepath = self.output_dir / filename
        filepath.parent.mkdir(parents=True, exist_ok=True)
        filepath.write_text(content)
        return filepath

    def save_logs(self, log_content: str, log_name: str | None = None) -> pathlib.Path:
        # always append to unified log file
        section = log_name or 'section'
        try:
            with self.main_log_file.open('a', encoding='utf-8') as fh:
                fh.write('\n' + ('-' * 60) + f'\n[{section.upper()}] {datetime.datetime.now().isoformat()}\n')
                fh.write(log_content.rstrip() + '\n')
        except Exception as e:
            logger.error(f'failed writing logs: {e}')
        return self.main_log_file

    def get_file_write_time(self, path: pathlib.Path) -> float:
        if not path.exists():
            return 0.0
        return path.stat().st_mtime


class ImageBuilder:
    def __init__(self, name: str, dockerfile_path: pathlib.Path, arch: str | None = None) -> None:
        self.name = name
        self.dockerfile_path = dockerfile_path
        self.arch = arch

    @staticmethod
    def get_image_tag(config: DevEnvironmentConfig) -> str:
        return f'dnv-{config.profile}-{config.distro}-{config.host_arch}:latest'

    def _image_exists(self, image_name: str) -> bool:
        return bool(
            subprocess.run(
                ContainerEngine.cmd('images', '-q', image_name), capture_output=True, text=True
            ).stdout.strip()
        )

    def _dockerfile_is_newer(self, dockerfile_path: pathlib.Path, image_name: str) -> bool:
        if not dockerfile_path.exists():
            return False

        if not self._image_exists(image_name):
            return True

        # both exist, compare timestamps as strings
        dockerfile_time = self._get_dockerfile_creation_time(dockerfile_path)
        image_time = self._get_image_creation_time(image_name)
        logger.debug(f'Dockerfile time {dockerfile_time}, image time {image_time}')

        return dockerfile_time > image_time

    def _get_dockerfile_creation_time(self, dockerfile_path: pathlib.Path) -> str:
        # convert file mtime to Docker's ISO timestamp format for comparison
        dt = datetime.datetime.fromtimestamp(dockerfile_path.stat().st_mtime, tz=datetime.timezone.utc)
        formatted = dt.strftime('%Y-%m-%dT%H:%M:%S.%f')
        return f'{formatted}Z'

    def _get_image_creation_time(self, image_name: str) -> str:
        result = subprocess.run(
            ContainerEngine.cmd('inspect', '--format', '{{.Created}}', image_name),
            capture_output=True,
            text=True,
        )
        if result.returncode != 0:
            # epoch as fallback
            return '1970-01-01T00:00:00.000000+00:00'

        return result.stdout.strip()

    def is_built(self) -> bool:
        return self._image_exists(self.name)

    def needs_rebuild(self) -> bool:
        return self._dockerfile_is_newer(self.dockerfile_path, self.name)

    def build(self) -> bool:
        logger.info(f'building image: {self.name}')
        dotfiles_dir = pathlib.Path.home() / '.dotfiles'

        build_cmd = ContainerEngine.cmd(
            'build',
            '-t',
            self.name,
            '-f',
            str(self.dockerfile_path),
        )

        if self.arch:
            build_cmd.extend(get_docker_platform_flag(self.arch))

        if logger.isEnabledFor(logging.DEBUG):
            build_cmd.extend(['--progress=plain', '--no-cache'])

        build_cmd.append(str(dotfiles_dir))
        logger.debug(f'running: {" ".join(build_cmd)}')

        artifact_repo = ArtifactRepository()

        if logger.isEnabledFor(logging.DEBUG):
            logger.info(f'Debug mode: showing verbose {ContainerEngine.engine()} build output...')
            build_result = subprocess.run(build_cmd, cwd=str(dotfiles_dir))
            returncode = build_result.returncode
            stdout_output = stderr_output = 'Live output shown above'
        else:
            # Standard mode - capture all output
            build_result = subprocess.run(build_cmd, capture_output=True, text=True, cwd=str(dotfiles_dir))
            returncode = build_result.returncode
            stdout_output = build_result.stdout
            stderr_output = build_result.stderr

        log_content = (
            f'Command: {" ".join(build_cmd)}\n'
            f'Return code: {returncode}\n'
            f'STDOUT:\n{stdout_output}\n'
            f'STDERR:\n{stderr_output}\n'
        )
        artifact_repo.save_logs(log_content, log_name='docker-build')

        if returncode != 0:
            logger.error(f'failed to build image {self.name}: {stderr_output.strip()}')
            return False
        logger.info(f'successfully built image: {self.name}')

        self._cleanup_dangling_images()
        return True

    def _cleanup_dangling_images(self):
        try:
            logger.debug('cleaning up dangling images...')
            result = subprocess.run(ContainerEngine.image_prune_cmd(), capture_output=True, text=True)
            if result.returncode == 0 and result.stdout.strip():
                logger.info('cleaned up dangling images')
                logger.debug(f'cleanup output: {result.stdout.strip()}')
        except Exception as e:
            logger.debug(f'failed to clean up dangling images: {e}')


class DevContainerManager:
    @staticmethod
    def is_running(container_id: str) -> bool:
        if not container_id:
            return False
        result = subprocess.run(
            ContainerEngine.cmd('inspect', '--format', '{{.State.Running}}', container_id),
            capture_output=True,
            text=True,
        )
        return result.returncode == 0 and result.stdout.strip() == 'true'

    @staticmethod
    def start(image_name: str, name: str | None, docker_config: dict, arch: str | None = None) -> str | None:
        cmd = ContainerEngine.cmd('run', '-it', '--label', 'devenv=true')

        # Add platform flag if cross-platform run is needed
        if arch:
            cmd.extend(get_docker_platform_flag(arch))

        if name:
            cmd.extend(['--name', name, '--label', f'devenv.container={name}'])

        for port in docker_config.get('exposed_ports', []):
            cmd.extend(['-p', f'{port}:{port}'])

        for volume in docker_config.get('volumes', []):
            source = pathlib.Path(volume['source']).expanduser().resolve()
            target = volume['target']
            mode = volume.get('mode', 'rw')
            cmd.extend(['-v', f'{source}:{target}:{mode}'])
        cmd.append(image_name)
        cmd.append('bash')
        logger.info(f'starting container: {" ".join(cmd)}')

        # replace the current python process with container engine - this exits Python
        # and drops directly into the interactive container
        os.execvp(ContainerEngine.engine(), cmd)

    @staticmethod
    def stop(container_id: str) -> bool:
        if not container_id:
            return False
        result = subprocess.run(ContainerEngine.cmd('stop', container_id), capture_output=True)
        return result.returncode == 0

    @staticmethod
    def remove(container_id: str) -> bool:
        if not container_id:
            return False
        result = subprocess.run(ContainerEngine.cmd('rm', container_id), capture_output=True, text=True)
        if result.returncode == 0:
            logger.info(f"container '{container_id}' removed successfully")
            return True
        else:
            logger.error(f"failed to remove container '{container_id}': {result.stderr.strip()}")
            return False

    @staticmethod
    def exec_command(container_id: str, command: list[str]) -> subprocess.CompletedProcess:
        if not container_id:
            raise RuntimeError('container not started')
        return subprocess.run(ContainerEngine.cmd('exec', '-it', container_id, *command))

    @staticmethod
    def is_healthy(container_id: str) -> bool:
        return DevContainerManager.is_running(container_id)

    @staticmethod
    def get_logs(container_id: str) -> str:
        if not container_id:
            return ''
        result = subprocess.run(ContainerEngine.cmd('logs', container_id), capture_output=True, text=True)
        return result.stdout if result.returncode == 0 else ''

    @staticmethod
    def start_existing_container(container_name: str) -> bool:
        if not container_name:
            return False
        result = subprocess.run(ContainerEngine.cmd('start', container_name), capture_output=True, text=True)
        if result.returncode == 0:
            logger.info(f"container '{container_name}' started successfully")
            return True
        else:
            logger.error(f"failed to start container '{container_name}': {result.stderr.strip()}")
            return False

    @staticmethod
    def container_exists(container_name: str) -> bool:
        if not container_name:
            return False
        result = subprocess.run(
            ContainerEngine.cmd('inspect', '--format', '{{.State.Status}}', container_name),
            capture_output=True,
            text=True,
        )
        return result.returncode == 0

    @staticmethod
    def exec_shell(container_id: str, shell: str = '/bin/bash') -> None:
        if not container_id:
            logger.warning('no container ID available')
            return
        result = subprocess.run(ContainerEngine.cmd('exec', '-it', container_id, shell))
        if result.returncode != 0:
            logger.error(f"failed to login to container '{container_id}' (ensure running)")

    @staticmethod
    def remove_volumes(container_name: str) -> bool:
        volume_result = subprocess.run(
            ContainerEngine.cmd(
                'volume',
                'ls',
                '--filter',
                f'label=devenv.container={container_name}',
                '-q',
            ),
            capture_output=True,
            text=True,
        )

        if volume_result.stdout.strip():
            volumes = volume_result.stdout.strip().split('\n')
            for volume in volumes:
                vol_del_result = subprocess.run(ContainerEngine.cmd('volume', 'rm', volume), capture_output=True)
                if vol_del_result.returncode == 0:
                    logger.info(f"volume '{volume}' removed")
                else:
                    logger.error(f"failed to remove volume '{volume}'")
            return True
        return False

    @staticmethod
    def list_deployments() -> list[dict]:
        result = subprocess.run(
            ContainerEngine.cmd(
                'ps',
                '-a',
                '--filter',
                'label=devenv=true',
                '--format',
                'table {{.Names}}\t{{.Image}}\t{{.Status}}\t{{.Ports}}',
            ),
            capture_output=True,
            text=True,
        )

        if result.returncode == 0:
            logger.info('devenv deployments:')
            for line in result.stdout.strip().splitlines():
                logger.info(f'{line}')
            return []
        else:
            logger.error(f'error listing deployments: {result.stderr.strip()}')
            return []


def get_dockerfile_name(config: DevEnvironmentConfig) -> pathlib.Path:
    devenv_dir = pathlib.Path.home() / '.dotfiles/.devenv'
    devenv_dir.mkdir(parents=True, exist_ok=True)
    return devenv_dir / f'Dockerfile.{config.profile}.{config.distro}.{config.host_arch}'


class CommandHandler:
    def __init__(self, args: argparse.Namespace):
        self.args = args
        self.artifact_repo = ArtifactRepository()

    def handle_spin(self) -> None:
        if self.args.profile not in DevEnvironmentConfig.PROFILES:
            available = list(DevEnvironmentConfig.PROFILES.keys())
            logger.error(f"profile '{self.args.profile}' not found. Available: {available}")
            sys.exit(1)

        config = DevEnvironmentConfig.from_profile(self.args.profile)
        dockerfile_path = get_dockerfile_name(config)

        image_name = ImageBuilder.get_image_tag(config)
        image_builder = ImageBuilder(image_name, dockerfile_path, config.host_arch)

        if not image_builder.is_built():
            logger.info(f'image {image_name} not found, building...')
            self.artifact_repo.save_artifact(DockerfileBuilder(config).build(), str(dockerfile_path))

            if not image_builder.build():
                logger.error('failed to build image')
                sys.exit(1)
        elif image_builder.needs_rebuild():
            logger.info('Dockerfile newer than image; rebuilding...')
            if not image_builder.build():
                logger.error('failed to build image')
                sys.exit(1)
        else:
            logger.info(f'using existing image: {image_name}')

        # This call will replace the current Python process with the Docker command
        # and never return - the user will be dropped directly into the container
        DevContainerManager.start(image_name, self.args.name, config.get_profile_data(), config.host_arch)

    def handle_build(self) -> None:
        if self.args.profile not in DevEnvironmentConfig.PROFILES:
            available = list(DevEnvironmentConfig.PROFILES.keys())
            logger.error(f"profile '{self.args.profile}' not found. Available: {available}")
            sys.exit(1)

        config = DevEnvironmentConfig.from_profile(self.args.profile)
        dockerfile_path = get_dockerfile_name(config)
        self.artifact_repo.save_artifact(DockerfileBuilder(config).build(), str(dockerfile_path))

        image_builder = ImageBuilder(ImageBuilder.get_image_tag(config), dockerfile_path, config.host_arch)
        if not image_builder.build():
            logger.error('failed to build image')
            sys.exit(1)
        logger.info(f"image '{ImageBuilder.get_image_tag(config)}' built successfully")

    def handle_craft(self) -> None:
        if self.args.profile not in DevEnvironmentConfig.PROFILES:
            available = list(DevEnvironmentConfig.PROFILES.keys())
            logger.error(f"profile '{self.args.profile}' not found. Available: {available}")
            sys.exit(1)

        config = DevEnvironmentConfig.from_profile(self.args.profile)

        dockerfile_content = DockerfileBuilder(config).build()
        filename = f'Dockerfile.{config.profile}.{config.distro}.{config.host_arch}'
        saved_path = self.artifact_repo.save_artifact(dockerfile_content, filename)
        logger.info(f'Dockerfile written to: {saved_path}')

    def handle_ls(self) -> None:
        DevContainerManager.list_deployments()

    def handle_rm(self) -> None:
        for name in self.args.names:
            logger.info(f"removing container '{name}'...")
            DevContainerManager.stop(name)
            success = DevContainerManager.remove(name)

            if success and hasattr(self.args, 'volumes') and self.args.volumes:
                DevContainerManager.remove_volumes(name)

            if not success:
                logger.error(f"failed to remove container '{name}'")
            else:
                logger.info(f"successfully removed '{name}'")

    def handle_shell(self) -> None:
        container_name = self.args.name

        if not container_name:
            logger.error('container name required for shell command')
            return

        if not DevContainerManager.container_exists(container_name):
            logger.error(f"container '{container_name}' does not exist")
            return

        if not DevContainerManager.is_running(container_name):
            logger.info(f"container '{container_name}' not running; starting...")
            if not DevContainerManager.start_existing_container(container_name):
                return

        time.sleep(1)

        DevContainerManager.exec_shell(container_name, self.args.shell)

    def handle_dotsync(self) -> None:
        if self.args.profile:
            if self.args.profile not in DevEnvironmentConfig.PROFILES:
                available = list(DevEnvironmentConfig.PROFILES.keys())
                logger.error(f"profile '{self.args.profile}' not found. Available: {available}")
                sys.exit(1)

            config = DevEnvironmentConfig.from_profile(self.args.profile)
            profile_data = config.get_profile_data()

            if 'dotfiles' not in profile_data:
                logger.error(f"no dotfiles configuration found in profile '{self.args.profile}'")
                sys.exit(1)

            DotfilesManager().install_dotfiles(profile_data['dotfiles'], self.args.source_dir)

    def handle(self):
        match self.args.command:
            case 'build':
                self.handle_build()
            case 'spin':
                self.handle_spin()
            case 'craft':
                self.handle_craft()
            case 'ls':
                self.handle_ls()
            case 'rm':
                self.handle_rm()
            case 'shell':
                self.handle_shell()
            case 'dotsync':
                self.handle_dotsync()
            case _:
                print('command not supported')


def main() -> None:
    parser = argparse.ArgumentParser(description='development Environment Manager')
    subparsers = parser.add_subparsers(dest='command', help='available commands')

    # spin command args
    spin_parser = subparsers.add_parser('spin', help='spin up development environment')
    spin_parser.add_argument(
        '--profile',
        default='workstation',
        help='profile name to use (default: workstation)',
    )
    spin_parser.add_argument('--name', help='container name')

    # build command args
    build_parser = subparsers.add_parser('build', help='build development environment')
    build_parser.add_argument(
        '--profile',
        default='workstation',
        help='profile name to use (default: workstation)',
    )

    # craft command args
    craft_parser = subparsers.add_parser('craft', help='generate Dockerfile')
    craft_parser.add_argument(
        '--profile',
        default='workstation',
        help='profile name to use (default: workstation)',
    )

    # dotsync command args
    dotsync_parser = subparsers.add_parser('dotsync', help='sync dotfiles')
    dotsync_parser.add_argument('--source-dir', help='source directory')
    dotsync_parser.add_argument(
        '--profile',
        default='workstation',
        help='profile name to use (default: workstation)',
    )

    # ls command args
    subparsers.add_parser('ls', help='list containers')

    # rm command args
    rm_parser = subparsers.add_parser('rm', help='remove container(s)')
    rm_parser.add_argument('names', nargs='+', help='container name(s) to remove')
    rm_parser.add_argument('--volumes', action='store_true', help='also delete volumes')

    # shell command args
    shell_parser = subparsers.add_parser('shell', help='shell into container')
    shell_parser.add_argument('name', help='container name')
    shell_parser.add_argument('--shell', default='/bin/bash', help='shell to use')

    args = parser.parse_args()

    if args.command is None:
        parser.print_help()
        print('\navailable profiles:')
        for profile_name, profile_data in DevEnvironmentConfig.PROFILES.items():
            print(f'- {profile_name}:')
            if 'distro' in profile_data:
                distro = profile_data['distro']
                if distro in DevEnvironmentConfig.DISTROS:
                    base_image = DevEnvironmentConfig.DISTROS[distro].base_image
                    print(f'  distro: {distro} ({base_image})')
                else:
                    print(f'  distro: {distro} (invalid)')
            if 'tools' in profile_data:
                tools = profile_data['tools']
                print(f'  tools: {", ".join(tools)}')
            if 'dotfiles' in profile_data:
                dotfiles = profile_data['dotfiles']
                print(f'  dotfiles: {len(dotfiles)} files')
            print()
        return

    CommandHandler(args).handle()


if __name__ == '__main__':
    main()
